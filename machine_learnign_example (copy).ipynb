{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "1bbf5157-debd-40ea-a220-54485dc7532c",
      "cell_type": "markdown",
      "source": "# Installing libraries",
      "metadata": {}
    },
    {
      "id": "b1756a67-cec8-4771-9730-3827b9d23e42",
      "cell_type": "code",
      "source": "%pip install pandas",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5ba4f8b5-f716-4346-9c2f-91a5be4e1ba9",
      "cell_type": "code",
      "source": "%pip install -U scikit-learn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0de4e175-f1a8-4974-b037-a660a2bc98f7",
      "cell_type": "markdown",
      "source": "# Importing data",
      "metadata": {}
    },
    {
      "id": "d7f32c02-d1a1-48bf-8f9b-0234953d6243",
      "cell_type": "code",
      "source": "import pandas as pd\n\ndata = pd.read_csv(\"melb_data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "01dab467-0f03-4044-8e75-414be08ee3fa",
      "cell_type": "markdown",
      "source": "# Cleaning data\n\nLooking inside the dataset you can see there are some missing values in the dataset. The easiest way ( although not alway the best) is to drop the missing values.",
      "metadata": {}
    },
    {
      "id": "064527e1-b7a1-4f58-8862-178dc010700d",
      "cell_type": "code",
      "source": "data.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "54852ee6-eb48-4cff-914c-13da71ee665e",
      "cell_type": "code",
      "source": "data = data.dropna(axis=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ace72176-833e-41f2-a978-423d2703bf08",
      "cell_type": "code",
      "source": "data.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a0139dca-51fe-48bd-a882-7dc5a4c6d7f7",
      "cell_type": "markdown",
      "source": "# Choosing prediction target and features\n\nTo choose a prediction target and features we will use for our prediction model first we need to see the avaible data. To do that in a more readable way we can provide list of column names.",
      "metadata": {}
    },
    {
      "id": "50eb72ed-0aee-41e3-a48b-311b09be1240",
      "cell_type": "code",
      "source": "data.columns",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "026ea719-28ed-4461-bb12-042b8cdd4c72",
      "cell_type": "markdown",
      "source": "Then using a dot notation we will select the column that will represent our prediction target - **y**. ",
      "metadata": {}
    },
    {
      "id": "4a21e5b6-f44a-4590-8484-4136557f03b9",
      "cell_type": "code",
      "source": "y = data.Price",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "114e250e-6002-423a-83f4-f57b48321fb0",
      "cell_type": "markdown",
      "source": "Using brackets we will select multiple columns as our features - **x**.",
      "metadata": {}
    },
    {
      "id": "523309c1-838d-4e00-9402-3317d38863cd",
      "cell_type": "code",
      "source": "features = ['Rooms', 'Landsize', 'Bathroom', 'Lattitude', 'Longtitude']\nx = data[features]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6f4004ed-5710-487f-98a3-af29b612aa26",
      "cell_type": "markdown",
      "source": "For quick data review we can use *describe()* method - it generates descriptive statistics.",
      "metadata": {}
    },
    {
      "id": "e62dac71-ab02-4b28-80a7-51efcacba3eb",
      "cell_type": "code",
      "source": "x.describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "59d8e50c-f748-40f1-8d2f-012db265218c",
      "cell_type": "markdown",
      "source": "# Creating ML Model\n\nOne of the most basic ML Model is Decision Tree - it has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes.\nAs seen above the data that we use both as a prediction target as well as features consists of contines numerical values. Because of that we will use *DecisonTreeRegressor* form scikit-learn library.",
      "metadata": {}
    },
    {
      "id": "0c207a64-6817-4c5d-bf99-109d68911871",
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor(random_state = 0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8e2d4d64-6689-41f2-87bb-443953515428",
      "cell_type": "markdown",
      "source": "Before we train our model it is a good time to divide our data into two subsets - one for training and one for testing. Failing to do so will lead to overfitting. One of the easiest method for random data spliting is *train_test_split* helper function.",
      "metadata": {}
    },
    {
      "id": "042c5208-a804-4e90-af45-8a2397332cd5",
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "65f701ea-4130-4e36-8c88-708426912263",
      "cell_type": "markdown",
      "source": "Now, we can train our model using training subset and predict and output for our testing data.",
      "metadata": {}
    },
    {
      "id": "b96b015f-b238-4d26-8d26-49962705e2f1",
      "cell_type": "code",
      "source": "model.fit(x_train, y_train)\nprediction = model.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8f8a2cd4-0ff2-4d3a-88ba-a5ddec0348b5",
      "cell_type": "markdown",
      "source": "Finally, we can use our *y_test* values and prediction output for *x_test* to score our model using *mean_absolute_error* and regression score.",
      "metadata": {}
    },
    {
      "id": "64ab8125-0bef-4d4a-9cc3-a4317a855a15",
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error, r2_score\n\nmae = mean_absolute_error(y_test, prediction)\nr2score = r2_score(y_test, prediction)\nprint(f'{mae=} {r2score=}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7711edd0-fe7e-4b8a-b8e2-9a5719925f3c",
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor\n\nmodel2 = RandomForestRegressor(n_estimators = 200)\n\nmodel2.fit(x_train, y_train)\nprediction2 = model2.predict(x_test)\nmae2 = mean_absolute_error(y_test, prediction2)\nr2score2 = r2_score(y_test, prediction2)\nprint(f'{mae=} {r2score=}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}